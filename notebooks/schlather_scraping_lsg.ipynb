{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from requests import session, get\n",
    "from urllib.parse import urljoin\n",
    "import shutil\n",
    "\n",
    "from typing import Dict, List"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Verschaffe dir mittels Chromes Entwicklertools einen Überblick über die Loginform auf [dieser](https://www.wim.uni-mannheim.de/schlather/teaching/aktuelle-semester/) Seite. Welche Daten werden alles benötigt und abgesendet?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Schreibe eine Funktion `materialien_login() -> requests.session`, welche sich auf der Seite einloggt und schließlich ein `request.session`-Objekt zurückgibt, welches u.A. alle Cookies enthält.** Achtung: es gibt zwei HTML-Forms auf der Seite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def materialien_login() -> requests.session:\n",
    "    login_url = \"https://www.wim.uni-mannheim.de/schlather/teaching/aktuelle-semester/\"\n",
    "    soup = BeautifulSoup(get(login_url).text, \"lxml\")\n",
    "    # Erstelle session objekt für Login\n",
    "    sess = requests.session()\n",
    "    # Logindaten\n",
    "    form_data = {\n",
    "        'user': '...',  # <--- Kommilitonen fragen :)\n",
    "        'pass': '...',  # <---       -\"-\n",
    "        'submit': 'Anmelden',\n",
    "        'logintype': 'login',\n",
    "        'pid': 0,\n",
    "        'redirect_url': '/schlather/teaching/aktuelle-semester/materialien/',\n",
    "        'tx_felogin_pi1[noredirect]': 0\n",
    "    }\n",
    "    # Login\n",
    "    sess.post(login_url, data=form_data)\n",
    "    # Gibt das Sessionobjekt zurück\n",
    "    return sess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Schreibe eine Funktion `scrape_pdfs(sess: requests.session) -> Dict[str, List[str]]`, welche für jede Vorlesung auf der Materialenseite die Links zu allen pdf-Dateien findet. Die Funktion erwartet als einziges Argument ein `requests.session` Objekt, das bereits auf der Seite eingeloggt ist. Die Funktion soll ein dictionary mit allen .pdf-Links pro Vorlesung zurückgeben.**\n",
    "\n",
    "Hinweis: Verwende `.replace(\"\\xad\", \"\")` um *HTML entities* aus dem Vorlesungsnamen (`str`) zu entfernen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_pdfs(sess: requests.session) -> Dict[str, List[str]]:\n",
    "    base_url = \"https://www.wim.uni-mannheim.de/schlather/teaching/aktuelle-semester/materialien/\"\n",
    "    soup = BeautifulSoup(sess.get(base_url).text, \"lxml\")\n",
    "    # Jede Vorlesung ist in einer 'gridelement accordion-item anchor' CSS Klasse:\n",
    "    res = {}\n",
    "    for vl in soup.find_all(class_=\"gridelement accordion-item anchor\"):\n",
    "        vl_name = vl.a.h4.text.replace(\"\\xad\", \"\")\n",
    "        # Finde alle .pdf Dateien: (alternativ: href=re.compile(r\"pdf$\"))\n",
    "        pdf_files = [ ]\n",
    "        for link in vl.find_all(\"a\", href=lambda h: h is not None and h.endswith(\"pdf\")):\n",
    "            pdf_files.append(urljoin(base_url, link[\"href\"]))\n",
    "        # Füge die Liste der .pdf-Links in das dict ein:\n",
    "        res[vl_name] = pdf_files\n",
    "    # Fertig\n",
    "    sess.close()\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Teste deinen Code, ob auch die Links richtig *geparsed* werden:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrape_pdfs(materialien_login())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Verwende die nachfolgende Funktion, um alle Dateien herunterzuladen:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "def download_file(sess: requests.session, url:str, pfad: pathlib.Path, filename: str) -> None:\n",
    "    req = get(url, stream=True)\n",
    "    if req.status_code == 200:\n",
    "        with open(pfad / filename, \"wb\") as f:\n",
    "            shutil.copyfileobj(req.raw, f)\n",
    "                \n",
    "def main(verbose=False) -> None:\n",
    "    # Scrape die Daten\n",
    "    sess = materialien_login()\n",
    "    daten = scrape_pdfs(sess)\n",
    "\n",
    "    # Lade jetzt die Dateien je Vorlesung\n",
    "    for vl_name, links in daten.items():\n",
    "        # Erstelle Ordner für VL, falls dieser noch nicht existiert\n",
    "        p = pathlib.Path().cwd() / vl_name.replace(\":\", \"\")\n",
    "        if not p.exists():\n",
    "            p.mkdir()\n",
    "        # Lade Dateien runter\n",
    "        for link in links:\n",
    "            dateiname = link.split(\"/\")[-1]\n",
    "            if verbose:\n",
    "                print(f\"Lade [{vl_name}]: {dateiname}...\")\n",
    "            download_file(sess, link, p, dateiname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zusatz: Das `sess` Objekt an jede Funktion mitzuschleppen ist irgendwie nervig und nicht unbedingt *pythonic*. Für größere Projekte ist es daher ratsam, sich eine Klasse zu schreiben**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}